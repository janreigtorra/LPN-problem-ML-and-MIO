{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the Learning Parity with Noise Problem using ML and MIO\n",
    "\n",
    "### INTRODUCTION AND MOTIVATION\n",
    "Imagine that Alice and Bob are two agents on a secret mission. Prior to every communication between them, they identify each other with the help of a shared secret key s. If Alice wants to identify herself to Bob, she needs to share her secret key with Bob so that Bob can verify that she is indeed Alice and not an imposter. However, by directly communicating the secret key s, an adversary may sniff the key and can later re-use it. Hence, this method of direct communication is not safe.\n",
    "To tackle this, Bob can instead ask Alice a set of questions that Alice can answer using her secret key. The questions can ask Alice to reveal some bits at a time but not all of them at once. The questions asked by Bob and the answers given by Alice can still be overheard by the adversary, however, now the adversary will have to reverse engineer the key from the set of questions and answers. It is difficult but still tractable since the key can be recovered by solving a system of linear equations if the set of questions and answers is known.\n",
    "However, Alice and Bob can still make the life of the adversary more difficult by adding slight random noise to the answers instead of providing the exact answers. The adversary will no longer be able to solve a linear system and the possibilities of the secret key will be exponential just by adding random noise. This is called Learning Parity with Noise (LPN) Problem.\n",
    "\n",
    "\n",
    "### PROBLEM STATEMENT \n",
    "Imagine you are the adversary. Solve the LPN Problem for an n-dimensional secret key $s ∈{0,1}^n$ over m questions given by question matrix $A ∈{0,1}^(m*n)$ and m answers given answer vector $b ∈{0,1}^m$. The answers can have random noise $e ∈{0,1}^m$ that follows a Bernoulli distribution with noise parameter p < 0.5. The relationship between the questions, answers, noise, and secret key is given by:\n",
    "\n",
    "$A*s+ e=b$\n",
    "\n",
    "**Intuition**\n",
    "Here, each row in matrix A represents a question about revealing specific bits of the secret key s. For example, over a 4-dimensional key s = [1 1 0 1], a question that asks about revealing the sum of 2nd and 4th bits will be represented by the vector [0 1 0 1]. The answer will be given by the XOR multiplication of matrix A with secret key s:\n",
    "$[0 \\ 1 \\ 0  \\ 1]*[1 \\ 1 \\ 0 \\ 1]^T=0*1+1*1+0*0+1*1=0+1+0+1=0$\n",
    "Hence, our answer is 0 which is represented by the corresponding row of vector b. We will have m such questions and answers. This process of revealing some but not all bits at a time is called HB Protocol .\n",
    "Now, e is our noise vector that follows Bernoulli’s distribution with probability p. This means that we flip a biased coin that returns heads (or 1) with probability p and tails (or 0) with probability 1-p.  In our previous example, if the corresponding element of the error vector is 0, we get our final answer as 0 + 0 = 0 (which corresponds to the correct sum). However, if the corresponding element of the error vector is 1, our final answer is 0 + 1 = 1 (which corresponds to the incorrect sum). Since e is an m-dimensional vector, it will have approximately p*m elements as 1. \n",
    "We want to recover the secret key s, given Bob’s input questions and Alice’s noisy output answers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET\n",
    "\n",
    "We will generate synthetic data for our problem using a fixed error probability (p < 0.5) and a secret key (s) of length n. Based on n and p, we will construct the dataset by simulating the question matrix A with dimensions m x n where m is given by : \n",
    "\n",
    "\n",
    "$m \\le 4*n*(0.5-p)^(-2)  \\ \\  \\ \\ \\ (A)$\n",
    "\n",
    "\n",
    "We will also simulate a noise vector e that follows a Bernoulli distribution with error probability p. Finally, we will generate our answer vector using the following equation:\n",
    "\n",
    "$(A*s + e)  \\% 2 = b   \\ \\ \\ \\ (B)$\n",
    "\n",
    "\n",
    "Here, we compute modulo 2 since A*s is XOR product and A*s + e is XOR addition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "using CSV, Tables, LinearAlgebra, Random, Gurobi, JuMP, Statistics, Random, Distributions, DataFrames, Combinatorics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "function generateDistribution(n, p)\n",
    "    m = floor(Int, n*p)\n",
    "    a = ones(Int, m)\n",
    "    b = zeros(Int, n-m)\n",
    "    res = [a;b]\n",
    "    return shuffle(res)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "Given a fixed p, we will train an ML model for a synthetic input matrix A and output vector b in order to recover the secret key s. Note that this problem is a classification problem since each element of b is either 0 or 1. We will try various classification techniques such as Logistic Regression, SVM, Optimal Feature Selection, CART, OCT, OCT-H, Random Forest Classifier, and XGBoost Classifier. We will perform 3-fold cross-validation for hyperparameter tuning for sparsity, minbucket, depth, number of trees, and estimators. \n",
    "Evaluation\n",
    "\n",
    "From our trained model, we will make predictions on test set $I^{(n*n)}$. We use the identity matrix of dimension n as our test set to recover each bit of the predicted secret key $\\hat{s}$. From our previous example, the multiplication of a 4x4 identity matrix with secret key s, gives the secret key itself. Hence, we should get predictions for the identity set on the trained ML model.\n",
    "\n",
    "To check our secret key $\\hat{s}$, we will compute how much our predicted answer differs from the true answer:\n",
    "\n",
    "$sum((A*\\hat{s}+b)  \\%  2)= error \\ \\ \\  (C)$\n",
    "\n",
    "\n",
    "Note that $(A*\\hat{s}+b)  \\%  2$ returns 1 if $A*\\hat{s}$ is different from b, otherwise it returns 0.\n",
    "We will also compute an error threshold to check if our error is small enough:\n",
    "$\\tau = p*m + \\delta                            \\ \\ \\     (D)$\n",
    "We will assume that the key is recovered if error ≤ τ. Note that we need to do these gymnastics to evaluate our model since we don’t have the real key from Alice but only her noisy answers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GlmNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "seed = 15095\n",
    "p = 0.05\n",
    "results = zeros(80, 6)\n",
    "num_result = 1\n",
    "for n=[4:2:32;]\n",
    "    test = Matrix(I, n, n);\n",
    "    m = floor(Int,4*n*((0.5-p)^(-2)))\n",
    "    threshold = ceil(Int, m*p + sqrt(n*m))\n",
    "    for ratio in [0, 0.125, 0.25, 0.375, 0.5]\n",
    "        s = generateDistribution(n, ratio)\n",
    "        count = 0\n",
    "        time1 = 0\n",
    "        for i=1:25\n",
    "            A = bitrand((m,n))\n",
    "            e = generateDistribution(m, p)\n",
    "            b = (A*s + e).%2;\n",
    "\n",
    "            # Train GLMNet\n",
    "            lnr = IAI.GLMNetCVClassifier(random_seed=seed) \n",
    "            grid = IAI.GridSearch(lnr, n_folds=5)\n",
    "            time1 = @elapsed IAI.fit!(grid, A, b)\n",
    "            best_lnr = IAI.get_learner(grid)\n",
    "            auc = round(IAI.score(best_lnr, A, b, positive_label=1, criterion=:auc), digits=2)\n",
    "            s_pred = IAI.predict(best_lnr, test);\n",
    "\n",
    "            # Verify Correctness\n",
    "            error = sum((A*s_pred+b).%2)\n",
    "            if error <= threshold\n",
    "                count += 1\n",
    "            end\n",
    "\n",
    "            # Print Result\n",
    "            println(\"For n=$n, ratio=$ratio, threshold=$threshold, key $s, i=$i, auc=$auc, error=$error\")        \n",
    "        end   \n",
    "        result = [n, m, threshold, ratio, count, time1]\n",
    "        results[num_result, :] = result\n",
    "        num_result += 1\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "seed = 15095\n",
    "p = 0.05\n",
    "results = zeros(80, 4)\n",
    "num_result = 1\n",
    "for n=[4:2:32;]\n",
    "    test = Matrix(I, n, n);\n",
    "    m = floor(Int,4*n*((0.5-p)^(-2)))\n",
    "    threshold = ceil(Int, m*p + sqrt(n*m))\n",
    "    for ratio in [0, 0.125, 0.25, 0.375, 0.5]\n",
    "        s = generateDistribution(n, ratio)\n",
    "        count = 0\n",
    "        for i=1:25\n",
    "            A = bitrand((m,n))\n",
    "            e = generateDistribution(m, p)\n",
    "            b = (A*s + e).%2;\n",
    "\n",
    "            # Train \n",
    "            lnr = IAI.XGBoostClassifier(random_seed=seed) \n",
    "            grid = IAI.GridSearch(lnr, max_depth=setDepth(n), num_rounds=[20, 50, 100])\n",
    "            time = @elapsed IAI.fit!(grid, A, b)\n",
    "            best_lnr = IAI.get_learner(grid)\n",
    "            auc = round(IAI.score(best_lnr, A, b, positive_label=1, criterion=:auc), digits=2)\n",
    "            s_pred = IAI.predict(best_lnr, test);\n",
    "\n",
    "            # Verify Correctness\n",
    "            error = sum((A*s_pred+b).%2)\n",
    "            if error <= threshold\n",
    "                count += 1\n",
    "            end\n",
    "\n",
    "            # Print Result\n",
    "            println(\"For n=$n, ratio=$ratio, threshold=$threshold, key $s, i=$i, auc=$auc, error=$error\")        \n",
    "        end   \n",
    "        result = [n, m, threshold, ratio, count, time]\n",
    "        results[num_result, :] = result\n",
    "        num_result += 1\n",
    "    end\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "seed = 15095\n",
    "p = 0.05\n",
    "results = zeros(80, 4)\n",
    "num_result = 1\n",
    "for n=[4:2:32;]\n",
    "    test = Matrix(I, n, n);\n",
    "    m = floor(Int,4*n*((0.5-p)^(-2)))\n",
    "    threshold = ceil(Int, m*p + sqrt(n*m))\n",
    "    for ratio in [0, 0.125, 0.25, 0.375, 0.5]\n",
    "        s = generateDistribution(n, ratio)\n",
    "        count = 0\n",
    "        for i=1:25\n",
    "            A = bitrand((m,n))\n",
    "            e = generateDistribution(m, p)\n",
    "            b = (A*s + e).%2;\n",
    "\n",
    "            # Train \n",
    "            lnr = IAI.XGBoostClassifier(random_seed=seed) \n",
    "            grid = IAI.GridSearch(lnr, max_depth=setDepth(n), num_rounds=[20, 50, 100])\n",
    "            time = @elapsed IAI.fit!(grid, A, b)\n",
    "            best_lnr = IAI.get_learner(grid)\n",
    "            auc = round(IAI.score(best_lnr, A, b, positive_label=1, criterion=:auc), digits=2)\n",
    "            s_pred = IAI.predict(best_lnr, test);\n",
    "\n",
    "            # Verify Correctness\n",
    "            error = sum((A*s_pred+b).%2)\n",
    "            if error <= threshold\n",
    "                count += 1\n",
    "            end\n",
    "\n",
    "            # Print Result\n",
    "            println(\"For n=$n, ratio=$ratio, threshold=$threshold, key $s, i=$i, auc=$auc, error=$error\")        \n",
    "        end   \n",
    "        result = [n, m, threshold, ratio, count, time]\n",
    "        results[num_result, :] = result\n",
    "        num_result += 1\n",
    "    end\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCT-H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "seed = 15095\n",
    "p = 0.05\n",
    "results = zeros(80, 6)\n",
    "num_result = 1\n",
    "for n=[4:2:32;]\n",
    "    test = Matrix(I, n, n);\n",
    "    m = floor(Int,4*(n^1.5)*((0.5-p)^(-2)))\n",
    "    threshold = ceil(Int, m*p + sqrt(n*m))\n",
    "    for ratio in [0, 0.125, 0.25, 0.375, 0.5]\n",
    "        s = generateDistribution(n, ratio)\n",
    "        count = 0\n",
    "        for i=1:25\n",
    "            A = bitrand((m,n))\n",
    "            e = generateDistribution(m, p)\n",
    "            b = (A*s + e).%2;\n",
    "\n",
    "            # Train OCT-H\n",
    "            lnr = IAI.OptimalTreeClassifier(random_seed=seed, hyperplane_config=Dict(\"sparsity\"=>:all)) \n",
    "            grid = IAI.GridSearch(lnr, max_depth=setDepth(n), minbucket=[3,4,5])\n",
    "            IAI.fit!(grid, A, b)\n",
    "            best_lnr = IAI.get_learner(grid)\n",
    "            auc = round(IAI.score(best_lnr, A, b, positive_label=1, criterion=:auc), digits=2)\n",
    "            s_pred = IAI.predict(best_lnr, test);\n",
    "\n",
    "            # Verify Correctness\n",
    "            error = sum((A*s_pred+b).%2)\n",
    "            if error <= threshold\n",
    "                count += 1\n",
    "            end\n",
    "\n",
    "            # Print Result\n",
    "            println(\"For n=$n, ratio=$ratio, threshold=$threshold, key $s, i=$i, auc=$auc, error=$error\")        \n",
    "        end   \n",
    "        result = [n, threshold, ratio, count]\n",
    "        results[num_result, :] = result\n",
    "        num_result += 1\n",
    "    end\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "seed = 15095\n",
    "p = 0.05\n",
    "results = zeros(80, 4)\n",
    "num_result = 1\n",
    "for n=[10:2:32;]\n",
    "    test = Matrix(I, n, n);\n",
    "    m = floor(Int,4*n*((0.5-p)^(-2)))\n",
    "    threshold = ceil(Int, m*p + sqrt(n*m))\n",
    "    for ratio in [0, 0.125, 0.25, 0.375, 0.5]\n",
    "        s = generateDistribution(n, ratio)\n",
    "        count = 0\n",
    "        for i=1:25\n",
    "            A = bitrand((m,n))\n",
    "            e = generateDistribution(m, p)\n",
    "            b = (A*s + e).%2;\n",
    "\n",
    "            # Train RF\n",
    "            lnr = IAI.RandomForestClassifier(random_seed=seed) \n",
    "            grid = IAI.GridSearch(lnr, max_depth=setDepth(n), minbucket=[3,4,5], num_trees=[10, 25, 50])\n",
    "            time = @elapsed IAI.fit!(grid, A, b)\n",
    "            best_lnr = IAI.get_learner(grid)\n",
    "            auc = round(IAI.score(best_lnr, A, b, positive_label=1, criterion=:auc), digits=2)\n",
    "            s_pred = IAI.predict(best_lnr, test);\n",
    "\n",
    "            # Verify Correctness\n",
    "            error = sum((A*s_pred+b).%2)\n",
    "            if error <= threshold\n",
    "                count += 1\n",
    "            end\n",
    "\n",
    "            # Print Result\n",
    "            println(\"For n=$n, ratio=$ratio, threshold=$threshold, key $s, i=$i, auc=$auc, error=$error\")        \n",
    "        end   \n",
    "        result = [n, m, threshold, ratio, count, time]\n",
    "        results[num_result, :] = result\n",
    "        num_result += 1\n",
    "    end\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Integer Optimization\n",
    "\n",
    "Given a fixed p, we will solve an MIO problem for a synthetic input matrix A and output vector b in order to recover the secret key s. Note that this problem will be a mixed-integer problem since each element of key s is either 0 or 1 and b is the XOR product of A and s plus some error term. The advantage of this approach will be that it will always recover the key for reasonable number of samples, unlike the ML models.\n",
    "\n",
    "Our objective will be to minimize the difference between A*s and b since this difference corresponds to our Bernoulli error p:\n",
    "\n",
    "$$min_{s\\in\\{ 0,1 \\}^n }     \\sum_{j=1}^m |a_j*s_j-b_j |$$\n",
    "\n",
    "Now since everything is a XOR operation here, we need to model the constraints of XOR multiplication and XOR addition. To be able to do that, for every multiplication and addition operation, we need to compute the result of the operation modulus 2. Let $h_j$ be the remainder when $a_j*s_j$ is divided by 2. Our objective now becomes:\n",
    "\n",
    "$$min_{s\\in\\{ 0,1 \\}^n }     \\sum_{j=1}^m |h_j-b_j |$$\n",
    "$$s.t.      \\sum_{i=1}^n A_{ji}*s_i =2y_j+h_j                \\ \\   j\\in m$$\n",
    "$$h,y \\ge 0$$\n",
    "$$h_j<2                                               j\\in m$$     \n",
    "$$s\\in\\{ 0,1 \\}^n, h \\in R^m, y \\in Z^m$$\n",
    "\n",
    "\n",
    "\n",
    "We’re almost there, now let’s linearize it and get the final MIO formulation!\n",
    "\n",
    "\n",
    "\n",
    "**MIO Formulation**: \n",
    "\n",
    "\n",
    "min_{s,h,z,y} \\sum_{j=1}^m z_j \n",
    "$$s.t.      \\sum_{i=1}^n A_{ji}*s_i =2y_j+h_j                \\ \\   j\\in m$$\n",
    "$$h_j -b_j<_j                                               j\\in m$$     \n",
    "$$-h_j + b_j<_j                                               j\\in m$$     \n",
    "$$h,y,z \\ge 0$$\n",
    "$$h_j<2                                               j\\in m$$     \n",
    "$$s\\in\\{ 0,1 \\}^n, h,z \\in R^m, y \\in Z^m$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "function MIO(A,b,n,m)\n",
    "    model = Model(Gurobi.Optimizer)\n",
    "    set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "    set_optimizer_attribute(model, \"TimeLimit\", 1800)  # limit 30 minutes \n",
    "    epsilon = 0.0001\n",
    "\n",
    "    # Add variables\n",
    "    @variable(model, s[i=1:n], Bin)\n",
    "    @variable(model, h[j = 1:m] >= 0)\n",
    "    @variable(model, z[j = 1:m] >= 0)\n",
    "    @variable(model, y[j = 1:m] >= 0, Int)\n",
    "\n",
    "    @objective(model, Min, sum(z[j] for j = 1:m))\n",
    "\n",
    "    @constraint(model, [j=1:m] ,   h[j] - b[j]  <= z[j])\n",
    "    @constraint(model, [j=1:m] , - h[j] + b[j]  <= z[j])\n",
    "    @constraint(model, [j=1:m] , sum(A[j,i]*s[i] for i = 1:n)  == 2*y[j] + h[j])\n",
    "    @constraint(model, [j=1:m] ,  h[j] <= 2 - epsilon)\n",
    "\n",
    "    time1 = @elapsed optimize!(model)\n",
    "    return value.(s), time1\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "seed = 15095\n",
    "p = 0.1\n",
    "results = zeros(5000, 6)\n",
    "num_result = 1\n",
    "for n=[4:2:20;]\n",
    "    test = Matrix(I, n, n);\n",
    "    M = floor(Int,4*n*((0.5-p)^(-2)) )\n",
    "    for ratio in [0, 0.25, 0.5, 0.75, 1]\n",
    "        s = generateDistribution(n, ratio)\n",
    "\n",
    "        for m = [Int(trunc(M/50)):Int(trunc(M/50)):Int(trunc(M/10));] \n",
    "            count = 0\n",
    "            threshold = ceil(Int, m*p + sqrt(n*m))\n",
    "            A = bitrand((m,n))\n",
    "            e = rand(Binomial(1,p), m)\n",
    "            b = (A*s + e).%2;\n",
    "\n",
    "            # Solve MIO\n",
    "            s_pred, time1 =  MIO(A,b,n,m);\n",
    "\n",
    "            # Verify Correctness\n",
    "            error = sum((A*s_pred+b).%2)\n",
    "            if error < threshold\n",
    "                count += 1\n",
    "            end\n",
    "        \n",
    "            # Print Result\n",
    "            println(\"For n=$n, ratio=$ratio, threshold=$threshold, key $s, m=$m,  error=$error\")          \n",
    "            result = [n, m, threshold, ratio, count, time1] # count 1 recovered\n",
    "            results[num_result, :] = result\n",
    "            num_result += 1\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute Force Algorithm\n",
    "We will also use the Brute-Force algorithm to find the secret key s by iterating over all possible keys until a given key satisfies the threshold criteria in (D). The solution from this approach will serve as a benchmark both in terms of correctness as well as time complexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "function brute_force(s,t,A,b)\n",
    "    n = length(s)    \n",
    "    tic = now()\n",
    "    # Generate new s\n",
    "    for i in 0:n\n",
    "        s_f = vcat(repeat([1],i), repeat([0],n-i))\n",
    "        for s_try in multiset_permutations(s_f,length(s_f)) \n",
    "            if sum((A*s_try+b).%2) <= t\n",
    "                return s_try\n",
    "            end\n",
    "\n",
    "            toc = now()\n",
    "            if toc-tic > Minute(30)\n",
    "                return s_try\n",
    "            end\n",
    "        end \n",
    "    end \n",
    "\n",
    "end \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "seed = 15095\n",
    "p = 0.1\n",
    "results = zeros(5000, 6)\n",
    "num_result = 1\n",
    "for n=[4:2:20;]\n",
    "#for n=[4:2:4;]\n",
    "    test = Matrix(I, n, n);\n",
    "    M = floor(Int,4*n*((0.5-p)^(-2)) )\n",
    "    for ratio in [0, 0.25, 0.5, 0.75, 1]\n",
    "        s = generateDistribution(n, ratio)\n",
    "\n",
    "        for m = [Int(trunc(M/50)):Int(trunc(M/50)):Int(trunc(M/10));] \n",
    "            count = 0\n",
    "            threshold = ceil(Int, m*p)\n",
    "            A = bitrand((m,n))\n",
    "            e = generateDistribution(m, p)\n",
    "            b = (A*s + e).%2;\n",
    "\n",
    "            # Solve Brute force\n",
    "            s_pred = brute_force(s,threshold,A,b);\n",
    "            time1 =  @elapsed brute_force(s,threshold,A,b);\n",
    "\n",
    "            # Verify Correctness\n",
    "            error = sum((A*s_pred+b).%2)\n",
    "            if error <= threshold\n",
    "                count += 1\n",
    "            end\n",
    "            recover = (s_pred == s)\n",
    "            # Print Result\n",
    "            println(\"For n=$n, ratio=$ratio, threshold=$threshold, key $s, m=$m, recover=$recover, error=$error\")          \n",
    "            result = [n, m, threshold, ratio, count, time1] # count 1 recovered\n",
    "            results[num_result, :] = result\n",
    "            num_result += 1\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
